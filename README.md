# TBank Logo Detection

**Работу выполнил: Близниченко Алексей в рамках отбора на смену ML в Сириус**

<details open>
<summary>Разделы</summary>

<!-- TOC -->
<!-- TOC -->

</details>

# Установка и запуск

# Подход к решению

При первоначальной оценке сложности предстоящей работы, я определился со стэком технологий и провел сравнительный анализ. Конкретно для ручной и затем полуавтоматической разметки данных я выбрал open-source приложение [Label Studio](https://github.com/HumanSignal/label-studio/) в силу положительных отзывов, удобства работы и перспектив подключения своей модели для предразметки изображений. Затем я изучил текущие state-of-the-art модели для детекции объектов на изображении и остановился на линейке [YOLO](https://docs.ultralytics.com/ru/models/), с которыми я имею опыт работы и которые проверены временем. Из них я решил провести сравнение моделей v11 и v12 чтобы выбрать наиболее подходящую под решение задачи.

Следующим шагом я настроил пайплайн работы: изначально разметку я проводил вручную (первую 1000 изображений), затем собирал размеченные данные в датасет (800/200 обучение/валидация) при помощи простых самописных скриптов на Python, сохраняющих пропорцию изображений с логотипами и без них, и производил обучение YOLO в Google Colab. Затем модель я запускал уже локально и через [Label Studio ML Backend](https://github.com/HumanSignal/label-studio-ml-backend) и она производила предварительную разметку, которую я попровлял или принимал. 
Первая итерация обучения показала высокую точность обоих моделей, логотип детектировался практически идеально в различных интерфейсах, но иногда пропускался в других окружениях (3D модель, фотография, редкое цветовое сочетание). Тем не менее это был хороший результат для всего 1/30 данных. Из четырех моделей выбор пал на YOLOv11n, как более стабильную и эффективную модель, показавшую лучшие результаты по итогу обучения и учитывая результаты [исследования](https://arxiv.org/abs/2407.12040v7). Полные параметры обучения:
- Эпохи: **50**
- Patience: **10** эпох
- Приводимый размер изображения: **800x800** (подобрано эмпирически)
- Batch: **0.8** (рассчитывается так, чтобы при обучении использовалось 80% свободной памяти GPU)
- Кэширование: **на диске**
- GPU: **T4**

Результаты сравнения v11 и v12 на валидации:

| Модель   | Box Precision | Box Recall | Box mAP50 | Box mAP50-95 | Среднее время обучения 1 эпохи |
|----------|---------------|------------|-----------|--------------|--------------------------------|
| YOLOv11n | **0.996**     | 0.926      | **0.963** | **0.910**    | **~16 сек.**                   |
| YOLOv11s | 0.991         | 0.889      | 0.952     | 0.871        | ~22 сек.                       |
| YOLOv12n | 0.961         | 0.921      | 0.960     | 0.883        | ~23 сек.                       |
| YOLOv12s | 0.925         | **0.955**  | 0.889     | 0.820        | ~42 сек.                       |

Далее я решил модифицировать пайплайн и упростить работу. Для этого я арендовал облачный сервер через [Selectel](https://selectel.ru), где имел опыт работы с различными моделями, со следующими характеристиками:

- GPU: **T4**
- vCPU: **8 ядер**
- RAM: **8 ГБ**
- SSD: **45 ГБ, 200 МБ/с, 7000/4000 IOPS**
- OS: **Ubuntu 22.04 LTS 64-bit** (с предустановленным ПО для работы с моделями, в том числе CUDA 12.2, Python 3.10 и GPU Drivers 570)

На сервере я развернул инструменты как и ранее
